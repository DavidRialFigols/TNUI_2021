{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes i Classificaci√≥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest tercer lliurament es programar√† un classificador, que donat un tweet el categoritzar√† en una de les possibles classes. En aquesta ocasi√≥, implementareu un classificador amb tweets de pol√≠tics.\n",
    "\n",
    "\n",
    "**Qu√® s‚Äôha de fer?**\n",
    "\n",
    "Volem classificar tweets corresponents a diferents politics segons a quin partit pol√≠tic pertanyen. \n",
    "A partir de tots els tweets que tenim, crearem un vector de caracter√≠stiques que ens descrigui cada un dels tweets. \n",
    "Finalment desenvoluparem un classificador probabil√≠stic del tipus Naive Bayes que ens permeti identificar a quin partit pol√≠tic pertany un tweet donat segons les caracter√≠stiques triades.\n",
    "\n",
    "\n",
    "**Quina √©s la idea del sistema de classificaci√≥ que s‚Äôha de desenvolupar?**\n",
    "\n",
    "El classificador √©s un concepte de l'aprenentatge autom√†tic supervisat. \n",
    "L'objectiu del classificador √©s donat un vector de caracter√≠stiques que descriuen els objectes que es volen classificar indicar a quina categoria o classe pertanyen d'entre un conjunt predeterminat. \n",
    "El proc√©s de classificaci√≥ consta de dues parts: \n",
    "(a) el proc√©s d'aprenentatge i \n",
    "(b) el proc√©s d'explotaci√≥ o testeig. \n",
    "El proc√©s d'aprenentatge rep exemples de parelles $(x,y)$ on $x$ s√≥n les caracter√≠stiques, usualment nombres reals, i $y$ √©s la categoria a la que pertanyen. \n",
    "Aquest conjunt se'l coneix com a conjunt d'entrenament i ens servir√† per trobar una funci√≥ $\\hat{y}=h(x)$ que donada una $x$ aconsegueixi que $\\hat{y}=y$. Per altra banda el proc√©s de testeig aplica la funci√≥ $h(x)$ apresa a l'entrenament a una nova descripci√≥ per veure quina categoria li correspon.\n",
    "\n",
    "\n",
    "**Classificaci√≥ i llenguatge natural**\n",
    "\n",
    "La descripci√≥ dels exemples en caracter√≠stiques √©s el punt m√©s cr√≠tic de tot sistema d'aprenentatge autom√†tic. \n",
    "Una de les representacions m√©s simples per tal de descriure un text √©s la representaci√≥ *bag-of-words*.\n",
    "Aquesta representaci√≥ converteix un text en un vector de $N$ paraules. \n",
    "Consisteix en seleccionar un conjunt d'$N$ paraules i per cada paraula comptar quants cops apareix en el text. \n",
    "Una versi√≥ alternativa d'aquest proc√©s pot ser simplement indicar si apareix o no en el text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de comen√ßar\n",
    "\n",
    "\n",
    "**\\+ Durant la pr√†ctica, solament es podran fer servir les seg√ºents llibreries**:\n",
    "\n",
    "`Pandas, Numpy` i `NLTK`\n",
    "\n",
    "*Nota: A m√©s de les que ja es troben presents en la 1a cel¬∑la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i par√†metres ja donats**\n",
    "\n",
    "Aix√≤ no implica per√≤ que els h√†giu de fer servir. √âs a dir, que la funci√≥ tingui un par√†metre anomenat `df` no implica que l'h√†giu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica qu√® ser√† i de quin tipus cada un dels par√†metres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posar√† en el pydoc de la funci√≥), `df` sempre ser√† indicatiu del `Pandas.DataFrame` de les dades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "from os.path import join as path, dirname\n",
    "\n",
    "try:\n",
    "    from IPython.core.display import HTML\n",
    "\n",
    "    def pprint(df):\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(HTML(pd.DataFrame(df).to_html()))\n",
    "except:\n",
    "    def pprint(df):\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>√öltim acte de campanya! Aqu√≠ tossudament al√ßats i amb un somriure per fer cam√≠ cap a la #Rep√∫blica. Ho hem dit tan alt que l'Oriol @junqueras, avui, ens ha sentit des d'Estremera!</td>\n",
       "      <td>2017-12-19 20:12:01</td>\n",
       "      <td>785</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xavierdomenechs</td>\n",
       "      <td>comuns</td>\n",
       "      <td>#Badalona necessita uns pressupostos que posin la ciutadania al capdavant i que segueixin recuperant els drets socials que les retallades del PP van eliminar. La transformaci√≥ a Badalona no es pot aturar. Per aix√≤, tot el suport a @mariadolorsa.  \\n\\n#DolorsAlcaldessa</td>\n",
       "      <td>2018-04-27 10:04:19</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albert_rivera</td>\n",
       "      <td>cs</td>\n",
       "      <td>Encuentro Villac√≠s-Valls para lanzar una estrategia electoral com√∫n en Madrid y Barcelona</td>\n",
       "      <td>2018-11-17 20:34:58</td>\n",
       "      <td>357</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaumecollboni</td>\n",
       "      <td>psc</td>\n",
       "      <td>‚ÄúLa palabra es como una bala, no tiene retorno‚Äù interesante entrevista a ‚Å¶@mcampovidal‚Å©</td>\n",
       "      <td>2018-10-22 18:10:01</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albiol_xg</td>\n",
       "      <td>ppc</td>\n",
       "      <td>üìª Esta noche, a partir de las 22:10h, me entrevistan en @linternacope. ¬°Os espero!</td>\n",
       "      <td>2018-08-16 10:30:27</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 6)\n",
      "Test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avui hem repr√©s la Comissi√≥ Mixta amb el @govern: entenem q ha estat un any dif√≠cil per√≤ necessitem q Generalitat assumeixi les seves obligacions en temes tan b√†sics com habitatge, bressol, resid√®ncies gent gran o llei de barris. BCN no pot esperar m√©s:</td>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torra anunci√≥ un \"oto√±o caliente\" para aumentar la tensi√≥n, el conflicto y la fractura social en Catalu√±a y ahora sus comandos separatistas pretenden bloquear las calles de Barcelona. S√°nchez debe rectificar y defender a millones de catalanes ante los abusos del separatismo</td>\n",
       "      <td>856</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dem√† cal sortir als carrers per dir que #BarcelonaNoEstaEnVenda.\\n\\nVolem uns lloguers i un habitatge digne. \\n\\nNo permetrem que venguin les ciutats als fons voltors i especuladors.</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚ÄúCerc√†vem or i vam baixar a la mina.\\nI la foscor d‚Äôil¬∑lumin√† de sobte\\nperqu√® √©rem dos a contradir la nit‚Äù \\n\\nJoan Vinyoli</td>\n",
       "      <td>338</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Molt senzill d'entendre, companya: \\n1.- L'ALLIBERAMENT de dues persones innocents i honrades!\\n2.- LA LLIBERTAT: que no se'ns imposi el que hem de pensar i fer!\\n3.- REBUTJAR les amenaces, els tribunals, els fiscals i la policia al vostre servei per a fer oposici√≥! \\nS√≠, seny!</td>\n",
       "      <td>4932</td>\n",
       "      <td>7253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Training data')\n",
    "df_tweets_train = pd.read_excel(path('data', 'train.xlsx'), index_col='Id')\n",
    "pprint(df_tweets_train.head())\n",
    "print(df_tweets_train.shape)\n",
    "\n",
    "print('Test data')\n",
    "df_tweets_test = pd.read_excel(path('data', 'test.xlsx'), index_col='Id')\n",
    "pprint(df_tweets_test.head())\n",
    "print(df_tweets_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaci√≥\n",
    "\n",
    "Dividirem el notebook en 3 seccions que es complementen una a l'altra:\n",
    "\n",
    "1. An√†lisis de dades: Informaci√≥ b√†sica sobre els tweets\n",
    "2. Processament de les dades: Creaci√≥ d'un vector de caracter√≠stiques a partir dels tweets\n",
    "3. Classificaci√≥ amb Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√†lisis de dades\n",
    "\n",
    "El primer que haurem de fer √©s analitzar les dades mitjan√ßant diferents funcions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(df):\n",
    "    \"\"\"\n",
    "    Retorna el n√∫mero de tweets en el dataframe\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : n√∫mero de tweets\n",
    "    \"\"\"\n",
    "    return df.shape[0]\n",
    "\n",
    "def get_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna els usuaris dels pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Llista de strings amb els nom dels usuaris\n",
    "    \"\"\"\n",
    "    return df['username'].unique()\n",
    "\n",
    "def count_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Enter amb la quanitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    return len(get_politicians(df))\n",
    "\n",
    "def get_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna els partits pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Llista de strings amb els nom dels partits pol√≠tics que han tuitejat\n",
    "    \"\"\"\n",
    "    return df['party'].unique()\n",
    "\n",
    "def count_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de partits pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Enter amb la quanitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    return len(get_political_party(df))\n",
    "\n",
    "def count_tweet_politician(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per pol√≠tic\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : pd.Series amb la quantitat de tweets per pol√≠tic\n",
    "    \"\"\"\n",
    "    return df['username'].value_counts()\n",
    "\n",
    "def count_tweet_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per partit pol√≠tic\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : pd.Series amb la quantitat de tweets per partit pol√≠tic\n",
    "    \"\"\"\n",
    "    return df['party'].value_counts()\n",
    "\n",
    "def top_retweet(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets que han sigut m√©s retuitejats\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params n: n√∫mero de tweets per veure\n",
    "    :return : pd.Series amb els top retweets\n",
    "    \"\"\"\n",
    "    return df.nlargest(n, columns='retweet_count')['text']\n",
    "    \n",
    "def top_favorite(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets m√©s favorits\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params n: n√∫mero de tweets per veure\n",
    "    :return : pd.Series amb els top favorits\n",
    "    \"\"\"\n",
    "    return df.nlargest(n, columns='favorite_count')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "['martarovira' 'xavierdomenechs' 'albert_rivera' 'jaumecollboni'\n",
      " 'albiol_xg' 'miqueliceta' 'quimtorraipla' 'adacolau' 'santirodriguez'\n",
      " 'krls' 'joantarda' 'inesarrimadas'] 12\n",
      "['erc' 'comuns' 'cs' 'psc' 'ppc' 'jxcat'] 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Que una republicana defienda la Rep√∫blica es bastante previsible. De quien cuesta fiarse es de un republicano franc√©s que de repente se vuelve mon√°rquico. Libert√©, egalit√©, fraternit√©... se quedaron en los Pirineos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>A tots els dem√≤crates: no pararem fins que tornin a casa!#LlibertatPresosPol√≠tics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Una causa que necessiti ser defensada amb c√∫ters i cops de puny a periodistes (telemadrid i jordi borr√†s) √©s ben trista i no t√© futur, encara que tingui impunitat, diners i rei. Ho d√®iem fa uns dies: l'aporellos se'ls est√† anant de les mans.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>.@junqueras President d'un partit amb 86 anys d'hist√≤ria sense cap cas de corrupci√≥, √©s a la pres√≥ per inst√†ncia del partit m√©s corrupte d'Europa: el PP. I els seus imputats, on s√≥n? Esquiant, recol‚Ä¢locats a l'Ibex, i es veu que no troben un tal M. Rajoy \\nEl 21D, fem just√≠cia!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>Perdoneu, per√≤ aix√≤ √©s tan greu que si no hi ha conseq√º√®ncies, el sistema judicial espanyol de la monarquia far√† aig√ºes definitivament. En mans de qui est√† un dels pilars de tot sistema democr√†tic?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Que una republicana defienda la Rep√∫blica es bastante previsible. De quien cuesta fiarse es de un republicano franc√©s que de repente se vuelve mon√°rquico. Libert√©, egalit√©, fraternit√©... se quedaron en los Pirineos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Una causa que necessiti ser defensada amb c√∫ters i cops de puny a periodistes (telemadrid i jordi borr√†s) √©s ben trista i no t√© futur, encara que tingui impunitat, diners i rei. Ho d√®iem fa uns dies: l'aporellos se'ls est√† anant de les mans.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Acabo d'arribar a #Esc√≤cia convidat pel F√≤rum diplom√†tic @BeyondBorders__ per explicar el conflicte catal√†. Reprenem l‚Äôactivitat internacional per lluitar per la llibertat de la #Rep√∫blicaCatalana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>A tots els dem√≤crates: no pararem fins que tornin a casa!#LlibertatPresosPol√≠tics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Una gran #Diada2018 per avan√ßar cap a la rep√∫blica. No hi ha cap altre poble a Europa que hagi mobilitzat tants milions de persones, set anys seguits i sense incidents. Demanem votar el nostre futur i ser respectats com a naci√≥. Gr√†cies a tots els qui ho esteu fent possible!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(count_tweets(df_tweets_train))\n",
    "print(get_politicians(df_tweets_train), count_politicians(df_tweets_train))\n",
    "print(get_political_party(df_tweets_train), count_political_party(df_tweets_train))\n",
    "\n",
    "count_tweet_politician(df_tweets_train).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "count_tweet_party(df_tweets_train).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "pprint(top_retweet(df_tweets_train, 5))\n",
    "pprint(top_favorite(df_tweets_train, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptar paraules\n",
    "\n",
    "El primer que haurem d'implementar √©s la funci√≥ *normalize* que normalitzar√† les paraules.\n",
    "\n",
    "No modificar la seg√ºent cel¬∑la, s'encarrega de guardar una cach√© de la funci√≥ normalize per accelerar el proc√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    class memodict(dict):\n",
    "        def __init__(self, f):\n",
    "            self.f = f\n",
    "        def __call__(self, *args):\n",
    "            return self[args]\n",
    "        def __missing__(self, key):\n",
    "            ret = self[key] = self.f(*key)\n",
    "            return ret\n",
    "        \n",
    "    return memodict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'informatica'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Funcio creada per nosaltres per eliminar els accents i les dieresis d'una paraula\n",
    "def remove_accents_and_diaeresis(word):\n",
    "    \"\"\"\n",
    "    Retorna la paraula word sense accents ni dieresis.\n",
    "    Per exemple, si word = 'h√∂l√†i√©' retorna 'holaie'.\n",
    "    \n",
    "    :param word: paraula de la qual s'han de treure els accents i les dieresis.\n",
    "    :return : String amb la paraula sense accents ni dieresis.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = ''\n",
    "    for ch in word:\n",
    "        if (ch =='√°' or ch =='√†' or ch =='√§'):\n",
    "            result += 'a'\n",
    "        elif (ch =='√©' or ch =='√®' or ch =='√´'):\n",
    "            result += 'e'\n",
    "        elif (ch =='√≠' or ch =='√¨' or ch =='√Ø'):\n",
    "            result += 'i'\n",
    "        elif (ch =='√≥' or ch =='√≤' or ch =='√∂'):\n",
    "            result += 'o'\n",
    "        elif (ch =='√∫' or ch =='√π' or ch =='√º'):\n",
    "            result += 'u'\n",
    "        else:\n",
    "            result += ch\n",
    "    return result\n",
    "\n",
    "#Funcio creada per nosaltres per eliminar els apostrofs inicials i finals d'una paraula \n",
    "def remove_apostrophes(word):\n",
    "    \"\"\"\n",
    "    Retorna la paraula word sense apostrofs.\n",
    "    Per exemple, si word = \"l'Anna\" retorna \"Anna\".\n",
    "                 si word = \"veure'l\" retorna \"veure\".\n",
    "    \n",
    "    :param word: paraula de la qual s'han de treure els apostrofs.\n",
    "    :return : String amb la paraula sense apostrofs.\n",
    "    \"\"\"\n",
    "    #Fem un try perque tambe es possible que despres de l'apostrof s'acabi la paraula.\n",
    "    #Per exemple podria ser que word fos \"l'\", en aquest cas es retornaria \"l'\".\n",
    "    try:\n",
    "        if (word[1] == \"'\"):\n",
    "            word = word[2:]\n",
    "        if (word[len(word)-2] == \"'\"):\n",
    "            word = word[:-2]\n",
    "    except: \n",
    "        return word\n",
    "    return word\n",
    "\n",
    "@memo\n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Funci√≥ que donada una paraula la normalitzi\n",
    "    Exemple: inFO*Rm√Ä745tica? ---> informatica\n",
    "    \n",
    "    :param word: paraula a normalitzar\n",
    "    :return : paraula normalitzada\n",
    "    \"\"\"\n",
    "    #Eliminem els apostrofs de la paraula\n",
    "    word = remove_apostrophes(word)\n",
    "    #Eliminem tots els caracters de la paraula que no son lletres\n",
    "    word = ''.join([ch for ch in word.lower() if ch.isalpha()])\n",
    "    #Eliminem els accents i les dieresis de la paraula\n",
    "    word = remove_accents_and_diaeresis(word)\n",
    "    return word\n",
    "\n",
    "normalize('inFO*Rm√Ä745tica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taller', 'dels', 'nous', 'usos', 'de', 'la', 'informatica']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_to_words(sentence):\n",
    "    \"\"\"\n",
    "    Funci√≥ que donada una frase, generi una llista amb totes les seves paraules normalitzades.\n",
    "    \n",
    "    :param sentence: frase a transformar\n",
    "    :return : llista de paraules (no buides) normalitzades\n",
    "    \n",
    "    Exemple: **Taller DELS noUS U**SOS    de la inFO#Rm765√Ätica? ---> \n",
    "        ['taller', 'dels', 'nous', 'usos', 'de', 'la', 'informatica']\n",
    "    \"\"\"\n",
    "    #Retornem una llista amb les paraules normalitzades i filtrem la llista perque no hi hagin paraules 'buides'\n",
    "    return list(filter(lambda word: word != '', [normalize(word) for word in sentence.split()]))\n",
    "\n",
    "sentence_to_words('**Taller DELS noUS U**SOS    de la inFO#Rm765√Ätica?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de construir un DataFrame amb √≠ndex les paraules normalitzades,\n",
    "    i columnes n_ocur (nombre de vegades que apareix la paraula a tots els tweets)\n",
    "    i n_tweets (nombre de tweets on apareix la paraula alguna vegada).\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : DataFrame especificat.\n",
    "    \"\"\"\n",
    "    #Obtenim un pd.Series amb els tweets normalitzats\n",
    "    normalized = df['text'].apply(sentence_to_words)\n",
    "    #Obtenim un DataFrame on les files son els index dels tweets, les columnes\n",
    "    #son les paraules normalitzades i l'element de la posicio [i,j] es el nombre\n",
    "    #de vegades que la paraula j apareix al tweet i. (Quan una paraula apareix 0 cops, el valor es NaN)\n",
    "    occurrences = normalized.apply(pd.Series.value_counts)\n",
    "    #Obtenim un pd.Series amb el nombre de vegades que cada paraula apareix a tots els tweets\n",
    "    n_ocur = occurrences.sum(axis=0).astype(int)\n",
    "    #Obtenim un pd.Series amb el nombre de tweets on apareix cada paraula alguna vegada\n",
    "    n_tweets = occurrences.notna().sum(axis=0)\n",
    "    #Concatenem els 2 pd.Series per obtenir el DataFrame a retornar\n",
    "    result = pd.concat([n_ocur, n_tweets], axis=1)\n",
    "    \n",
    "    #Reanomenem les columnes i l'index\n",
    "    result.columns = ['n_ocur', 'n_tweets']\n",
    "    result.index.names = ['words']\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_ocur</th>\n",
       "      <th>n_tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>des</th>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hem</th>\n",
       "      <td>107</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap</th>\n",
       "      <td>68</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tossudament</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alt</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             n_ocur  n_tweets\n",
       "words                        \n",
       "des              49        46\n",
       "hem             107       100\n",
       "cap              68        60\n",
       "tossudament       2         2\n",
       "alt               4         4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = count_words(df_tweets_train)\n",
    "\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar paraules per partit pol√≠tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>des</th>\n",
       "      <th>hem</th>\n",
       "      <th>cap</th>\n",
       "      <th>tossudament</th>\n",
       "      <th>alt</th>\n",
       "      <th>somriure</th>\n",
       "      <th>avui</th>\n",
       "      <th>cami</th>\n",
       "      <th>tan</th>\n",
       "      <th>la</th>\n",
       "      <th>...</th>\n",
       "      <th>nefastas</th>\n",
       "      <th>conocian</th>\n",
       "      <th>siguieron</th>\n",
       "      <th>acumulan</th>\n",
       "      <th>aceleracion</th>\n",
       "      <th>bienal</th>\n",
       "      <th>malestares</th>\n",
       "      <th>desplazando</th>\n",
       "      <th>contemporaneo</th>\n",
       "      <th>incertidumbres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>party</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comuns</th>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>491</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erc</th>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>409</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jxcat</th>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>442</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppc</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 11137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        des  hem  cap  tossudament  alt  somriure  avui  cami  tan   la  ...  \\\n",
       "party                                                                    ...   \n",
       "comuns   10   26   15            0    0         2    55     7    6  491  ...   \n",
       "cs        2    2    0            0    0         0     4     0    2  400  ...   \n",
       "erc      17   24   27            2    1         1    53     7   14  409  ...   \n",
       "jxcat    13   34   19            0    2         2    34     6    4  442  ...   \n",
       "ppc       0    3    2            0    1         1    11     1    0  299  ...   \n",
       "\n",
       "        nefastas  conocian  siguieron  acumulan  aceleracion  bienal  \\\n",
       "party                                                                  \n",
       "comuns         0         0          0         1            1       1   \n",
       "cs             1         1          1         0            0       0   \n",
       "erc            0         0          0         0            0       0   \n",
       "jxcat          0         0          0         0            0       0   \n",
       "ppc            0         0          0         0            0       0   \n",
       "\n",
       "        malestares  desplazando  contemporaneo  incertidumbres  \n",
       "party                                                           \n",
       "comuns           1            1              1               1  \n",
       "cs               0            0              0               0  \n",
       "erc              0            0              0               0  \n",
       "jxcat            0            0              0               0  \n",
       "ppc              0            0              0               0  \n",
       "\n",
       "[5 rows x 11137 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_words_parties(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de construir un DataFrame amb columnes les paraules normalitzades,\n",
    "    i √≠ndex cadasc√∫n dels partits, contenint el nombre de vegades que cada paraula\n",
    "    ha aparegut a tweets del partit.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : DataFrame esmentat.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Creem una copia del DataFrame original per no modificar-lo\n",
    "    df_copy = df.copy()\n",
    "    #A la columna 'text' hi posem els tweets normalitzats\n",
    "    df_copy['text'] = df_copy['text'].apply(sentence_to_words)\n",
    "    \n",
    "    #Obtenim un DataFrame on les files son els indexs dels tweets, les columnes\n",
    "    #son les paraules normalitzades i l'element de la posicio [i,j] es el nombre\n",
    "    #de vegades que la paraula j apareix al tweet i. (Quan una paraula apareix 0 cops, el valor es NaN)\n",
    "    occurrences = df_copy['text'].apply(pd.Series.value_counts)\n",
    "    #Canviem els indexs del DataFrame occurrences pel nom del partit al qual pertany cada tweet\n",
    "    occurrences.index = df_copy['party']\n",
    "    \n",
    "    #Retornem un DataFrame amb les columnes les paraules normalitzades i index cadascun dels partits,\n",
    "    #contenint el nombre de vegades que cada paraula ha aparegut a tweets del partit\n",
    "    return occurrences.groupby(level=0).sum().astype(int)\n",
    "\n",
    "words_parties = count_words_parties(df_tweets_train)\n",
    "words_parties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraules m√©s freq√ºents als tweets\n",
    "\n",
    "\n",
    "**El problema de com escollir el vector de carecter√≠stiques**\n",
    "\n",
    "L'elecci√≥ de les paraules que formen el vector de caracter√≠stiques √©s un pas cr√≠tic. \n",
    "En funci√≥ de com de bona sigui aquesta descripci√≥, millor funcionar√† el sistema. \n",
    "Tot i que us deixem a vosaltres la pol√≠tica de creaci√≥ del vector de caracter√≠stiques us donem una d'exemple. \n",
    "Per saber quines paraules fer servir una possible estrat√®gia √©s agafar aquelles paraules que apareixen entre en un 10 i un 50 percent del total (sense tenir en compte el partit). \n",
    "Podeu experimentar variant aquests valors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_words = [\n",
    "                \"a\", \"de\", \"la\", \"el\", \"que\", \"una\", \"va\", \n",
    "                \"un\", \"i\", \"y\", \"per\", \"els\", \"les\", \"com\",\n",
    "                \"en\", \"del\", \"no\", \"es\", \"amb\", \"al\", \"hi\",\n",
    "                \"\", \"q\", \"d\", \"los\", \"las\", \"dels\", \"o\", \n",
    "                \"lo\", \"los\", \"para\", \"con\", \"ens\", \"ha\",\n",
    "                \"se\", \"esta\", \"como\", \"the\", \"su\", \"si\",\n",
    "                \"por\", \"mes\", \"mas\", \"hem\",\n",
    "                \"tot\", \"tots\", \"als\", \"fer\", \"he\", \"han\", \n",
    "                \"us\", \"van\", \"pel\", \"me\", \"of\", \"nos\", \"to\",\n",
    "                \"aquest\", \"molt\", \"sobre\", \"x\", \n",
    "                \"h\", \"e\", \"ni\", \"pero\"\n",
    "            ]\n",
    "\n",
    "# dep√®n de vosaltres emplenar aquesta llista amb possibles paraules a excloure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNwords(df, words, N, skip=[]):\n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un pd.Series amb √≠ndex cadasc√∫n dels partits,\n",
    "    i values una llista de les N paraules m√©s representatives \n",
    "    (les que apareixen amb m√©s freq√º√®ncia) de cadasc√∫n dels partits pol√≠tics.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :param words: diccionari amb les paraules i la seva frequencia\n",
    "    :param N: n√∫mero de paraules m√©s representatives que volem considerar\n",
    "    :return : pd.Series resultant.\n",
    "    \"\"\"\n",
    "    #Prenem nomes les paraules que ens interessen. Es a dir, eliminem les columnes\n",
    "    #corresponents a paraules que es troben a skip words\n",
    "    words_filtered = words.copy()\n",
    "    words_filtered = words_filtered.drop(skip, axis=1, errors='ignore')\n",
    "    #Ordenem les paraules per a cada partit segons el nombre de cops que apareixen a tweets del partit\n",
    "    ordered = words_filtered.apply(lambda row: sorted(pd.Series(zip(words_filtered.columns, row)),\n",
    "                                                      key=lambda cv: cv[1], reverse=True), axis=1)\n",
    "    #Prenem nomes les paraules i no els valors i ens quedem amb les N millors paraules per a cada partit\n",
    "    ordered = ordered.apply(lambda cell: np.array([x[0] for x in cell][:N]))\n",
    "    return ordered\n",
    "    \n",
    "top_words = topNwords(df_tweets_train, words_parties, 10, skip_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cara a millores, tingueu en compte que tamb√© haureu de filtrar aquelles paraules que apareixen en la majoria  de tweets, aix√≠ com tamb√©, les que √∫nicament apareixen en un conjunt molt petit de tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector de Caracter√≠stiques\n",
    "Creeu el vector de caracter√≠stiques necessari per a fer l‚Äôentrenament del Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, top_words): \n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un vector de caracter√≠stiques necessari per a l'entrenament del classificador Naive Bayes.\n",
    "    Retorna un DataFrame on cada fila representa el vector de caracter√≠stiques del corresponent tweet.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params top_words: ha de ser el pd.Series que retorna topNWords\n",
    "    :return : pd.DataFrame resultant.\n",
    "    \"\"\"\n",
    "    #Prenem una llista amb totes les paraules presents al pd.Series top_words\n",
    "    words = np.array(top_words.explode())\n",
    "    #Si hi ha paraules repetides, ens quedem nomes amb una copia\n",
    "    words = np.unique(words)\n",
    "    \n",
    "    #Obtenim un pd.Series amb els tweets normalitzats\n",
    "    normalized = df['text'].apply(sentence_to_words)\n",
    "    \n",
    "    #Definim la funcio f per aplicar a cada tweet normalitzat\n",
    "    f = lambda cell: [x in cell for x in words]\n",
    "    #Obtenim un pd.Series amb el vector de caracteristiques de cada tweet\n",
    "    features = normalized.apply(f)\n",
    "    \n",
    "    #Convertim els vectors de caracteristiques a DataFrame i els retornem\n",
    "    return pd.DataFrame(features.tolist(), index=features.index, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # Aquest parametre el podem canviar i fer proves per avaluar quin √©s el millor valor.\n",
    "\n",
    "words_parties = count_words_parties(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_parties, N, skip_words)\n",
    "features = create_features(df_tweets_train, top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El classificador Na√Øve Bayes\n",
    "\n",
    "Un cop tenim una representaci√≥ necessitem un proc√©s d'aprenentatge que ens permeti passar de la descripci√≥ a una categoria. \n",
    "En aquest lliurament farem servir el classificador Na√Øve Bayes. \n",
    "Aquest classificador forma part de la fam√≠lia de classificadors probabil√≠stics. \n",
    "La sortida d'un classificador probabil√≠stic √©s un valor de probabilitat donat un exemple per cadascuna de les categories. \n",
    "La decisi√≥ final correspon a la categoria amb m√©s probabilitat. \n",
    "\n",
    "\n",
    "Els classificadors probabilistics Bayesians es basen en el teorema de Bayes per realitzar els c√†lculs per trobar la probabilitat condicionada: \n",
    "$$ p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "d'on podem extreure que: \n",
    "$$ p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$\n",
    "\n",
    "\n",
    "En molts casos $p(y)$ i $p(x)$ s√≥n desconeguts i es consideren equiprobables. \n",
    "Per tant, la decisi√≥ es simplifica a:\n",
    "$$ p(y|x) = c ¬∑ p(x|y)$$\n",
    "\n",
    "\n",
    "Les deduccions fins a aquest punt s√≥n v√†lides per la majoria de classificadors Bayesians. \n",
    "Na√Øve Bayes es distingeix de la resta perqu√® imposa una condici√≥ encara m√©s restrictiva. \n",
    "Considerem $x=(x_1, \\cdots, x_n)$ un conjunt d'$N$ variables aleat√≤ries. \n",
    "Na√Øve Bayes assumeix que totes elles s√≥n independents entre elles i per tant podem escriure:\n",
    "$$p(x_1,x_2,...,x_N | y) = p(x_1|y)p(x_2|y)...p(x_N|y)$$\n",
    "\n",
    "\n",
    "Podem interpretar l'anterior equaci√≥ de la seg√ºent forma: La probabilitat de que el tweet descrit pel vector de caracter√≠stiques (0,1,0,1,1,1) sigui de la classe \"comuns\" √©s proporcional al producte de la probabilitat que la primera paraula del vector no aparegui en els tweets sobre \"comuns\"  per la probabilitat que la segona paraula s√≠ que hi aparegui, etc.\n",
    "\n",
    "\n",
    "**Estimant les probabilitats marginals condicionades**\n",
    "\n",
    "L'√∫ltim pas que ens queda √©s trobar el valor de les probabilitats condicionades. \n",
    "Farem servir la representaci√≥ de $0$'s i $1$'s indicant que la paraula no apareix (0) o s√≠ apareix (1) a al tweet. \n",
    "Per trobar el valor de la probabilitat condicionada farem servir una aproximaci√≥ freq√ºentista a la probabilitat. \n",
    "Aix√≤ vol dir que calcularem la freq√º√®ncia d'aparici√≥ de cada paraula per a cada categoria. \n",
    "Aquest c√†lcul es fa dividint el nombre de tweets de la categoria en que apareix la paraula pel nombre total de tweets d'aquella categoria. \n",
    "\n",
    "En general:\n",
    "$$p(x = \\text{\"badalona\"} | y = C)= \\frac{A}{B} $$\n",
    "on A √©s el n√∫mero de tweets de la categoria C on hi apareix la paraula 'badalona' i B √©s el n√∫mero total de tweets de la categoria C.\n",
    "\n",
    "\n",
    "### Punts d√®bils:\n",
    "\n",
    "**El problema de la probabilitat 0**\n",
    "\n",
    "Si us hi fixeu b√©, la probabilitat pot ser 0 !! \n",
    "Aix√≤ vol dir, que si en el tweet no hi apareix una paraula no pot ser classificada com un partit pol√≠tic.\n",
    "No sembla raonable que s'assigni o no en aquesta categoria segons si en el tweet hi apareix o no una √∫nica paraula. \n",
    "Per tant, el que s'acostuma a fer √©s donar una baixa probabilitat en comptes de zero. \n",
    "Una de les possibles solucions es fer servir la correcci√≥ de Laplace. \n",
    "Seguint l'exemple anterior la correcci√≥ de Laplace √©s\n",
    "$$p(x= \\text{\"badalona\"} | y = 'C' ) = \\frac{A+1}{B+M}$$ \n",
    "on M √©s el nombre de categories\n",
    "\n",
    "**El problema del \"underflow\"**\n",
    "\n",
    "La funci√≥ que hem de calcular en el Naive Bayes √©s un producte. \n",
    "El nombre de caract√©ristiques del vector √©s el nombre de termes del producte. \n",
    "Aquests nombres s√≥n iguals o menors a 1, si els multipliquem tots entre ells el resultat ser√† massa petit per a representar-lo en un nombre de punt flotant i el c√†lcul acabar√† sent redu√Øt a zero. \n",
    "Per solucionar aquest problema en comptes d'operar fent multiplicacions, se sol passar a l'escala logar√≠tmica i all√† operar fent servir sumes en comptes de multiplicacions.\n",
    "\n",
    "### Classificar:\n",
    "\n",
    "Donat un vector de caracter√≠stiques $x=(x_1,...,x_n)$, per classificar el que farem ser√† calcular la probabilitat de pert√†nyer a cada un dels partits pol√≠tics:\n",
    "\n",
    "$$p(\\text{comuns}|x) = p(\\text{comuns})\\prod_{i=1}^np(x_i|\\text{comuns})$$\n",
    "$$\\cdots$$\n",
    "$$p(\\text{psc}|x) = p(\\text{psc})\\prod_{i=1}^np(x_i|\\text{psc})$$\n",
    "\n",
    "I finalment, el tweet √©s del partit de probabilitat m√†xima. Tingues en compte que per $x_i = 0$ s'ha de considerar la probabilitat inversa, √©s a dir, la probabilitat de ser de la clase $C$ quan $x_i = 0$ ve donada per $1 - p(x_i|C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementeu la funci√≥ d'aprenentatge del classificador Na√Øve Bayes (funci√≥ **naive_bayes_learn()**). La funci√≥ ha de mostrar per pantalla el resultat obtingut \n",
    "L'**error d'entrenament** es troba calculant el percentatge d'errors que s'obtenen quan es fa el testeig amb les mateixes dades utilizades per fer entrenament (aprenentatge). Aquest error es un valor molt optimista de com funcionar√† el clasificador i mai s'ha de prendre com a mesura per comparar clasificadors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcio creada per nosaltres per comptar el nombre de tweets de cada partit on apareix cada paraula\n",
    "#Hem creat aquesta funcio per utilitzar-la des de la funcio naive_bayes_learn\n",
    "def count_words_tweet_parties(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que retorna un DataFrame amb columnes les paraules normalitzades,\n",
    "    i √≠ndex cadasc√∫n dels partits, contenint el nombre de tweets de cada partit on\n",
    "    ha aparegut cada paraula. A diferencia de count_words_parties(), en aquest cas si\n",
    "    una paraula apareix dues vegades a un mateix tweet nomes es compta una sola vegada,\n",
    "    mentre que en la funcio count_words_parties() es compta dues vegades.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : DataFrame esmentat.\n",
    "    \"\"\"\n",
    "    #Creem una copia del DataFrame original per no modificar-lo\n",
    "    df_copy = df.copy()\n",
    "    #Obtenim un pd.Series amb els tweets normalitzats\n",
    "    normalized = df_copy['text'].apply(sentence_to_words)\n",
    "    #Canviem els indexs del pd.Series normalized pel nom del partit al qual pertany cada tweet\n",
    "    normalized.index = df_copy['party']\n",
    "    \n",
    "    #Obtenim un DataFrame on les files son els noms dels partits al qual pertany cada tweet, les columnes\n",
    "    #son les paraules normalitzades i l'element de la posicio [i,j] es el nombre\n",
    "    #de vegades que la paraula j apareix al tweet i. (Quan una paraula apareix 0 cops, el valor es NaN)\n",
    "    occurrences = normalized.apply(pd.Series.value_counts)\n",
    "    #Retornem el nombre de tweets de cada partit on apareix cada paraula\n",
    "    return occurrences.notna().groupby(level=0).sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>des</th>\n",
       "      <th>hem</th>\n",
       "      <th>cap</th>\n",
       "      <th>tossudament</th>\n",
       "      <th>alt</th>\n",
       "      <th>somriure</th>\n",
       "      <th>avui</th>\n",
       "      <th>cami</th>\n",
       "      <th>tan</th>\n",
       "      <th>la</th>\n",
       "      <th>...</th>\n",
       "      <th>nefastas</th>\n",
       "      <th>conocian</th>\n",
       "      <th>siguieron</th>\n",
       "      <th>acumulan</th>\n",
       "      <th>aceleracion</th>\n",
       "      <th>bienal</th>\n",
       "      <th>malestares</th>\n",
       "      <th>desplazando</th>\n",
       "      <th>contemporaneo</th>\n",
       "      <th>incertidumbres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>party</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comuns</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erc</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jxcat</th>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppc</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psc</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows √ó 11137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        des  hem  cap  tossudament  alt  somriure  avui  cami  tan   la  ...  \\\n",
       "party                                                                    ...   \n",
       "comuns   10   23   13            0    0         2    55     6    5  241  ...   \n",
       "cs        2    2    0            0    0         0     3     0    2  215  ...   \n",
       "erc      16   23   22            2    1         1    52     6   13  216  ...   \n",
       "jxcat    12   33   18            0    2         2    33     6    4  228  ...   \n",
       "ppc       0    3    2            0    1         1    11     1    0  180  ...   \n",
       "psc       6   16    5            0    0         0    28     1    0  213  ...   \n",
       "\n",
       "        nefastas  conocian  siguieron  acumulan  aceleracion  bienal  \\\n",
       "party                                                                  \n",
       "comuns         0         0          0         1            1       1   \n",
       "cs             1         1          1         0            0       0   \n",
       "erc            0         0          0         0            0       0   \n",
       "jxcat          0         0          0         0            0       0   \n",
       "ppc            0         0          0         0            0       0   \n",
       "psc            0         0          0         0            0       0   \n",
       "\n",
       "        malestares  desplazando  contemporaneo  incertidumbres  \n",
       "party                                                           \n",
       "comuns           1            1              1               1  \n",
       "cs               0            0              0               0  \n",
       "erc              0            0              0               0  \n",
       "jxcat            0            0              0               0  \n",
       "ppc              0            0              0               0  \n",
       "psc              0            0              0               0  \n",
       "\n",
       "[6 rows x 11137 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = count_words_tweet_parties(df_tweets_train)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_learn(df, feats):\n",
    "    \"\"\"\n",
    "    Funci√≥ que estima les probabilitats marginals condicionades.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada (atribut party)\n",
    "    :params feats: DataFrame de features de cada tweet.\n",
    "    :return : DataFrame amb les probabilitats marginals condicionades amb la correcci√≥ de Laplace,\n",
    "        on files s√≥n les feature words, i columnes s√≥n els partits.\n",
    "    \"\"\"\n",
    "    #Calculem el nombre de tweets de cada partit on apareix cada paraula\n",
    "    words_parties = count_words_tweet_parties(df)\n",
    "    #Calculem el nombre de tweets que ha fet cada partit\n",
    "    count_tweets_parties = count_tweet_party(df)\n",
    "    #Calculem el nombre de partits politics\n",
    "    num_parties = count_political_party(df)\n",
    "    \n",
    "    #Eliminem del DataFrame words_parties totes les columnes (i.e. paraules) que no son en feats\n",
    "    result = words_parties[feats.columns]\n",
    "    #Definim la funcio f a aplicar al DataFrame (corresponent a la probabilitat amb la correccio de Laplace)\n",
    "    f = lambda row: (1 + row) / (count_tweets_parties[row.index] + num_parties)\n",
    "    #Calculem les probabilitats marginals condicionades amb la correcci√≥ de Laplace\n",
    "    result = result.apply(f)\n",
    "    #Retornem el resultat transposat per retornar a les files les feature words i a les columnes els partits\n",
    "    return result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, split):\n",
    "    \"\"\"\n",
    "    Funci√≥ que separa les dades en training i test\n",
    "    \n",
    "    :param df:\n",
    "    :param split: proporci√≥ de les dades que ser√†n per l'entrenament\n",
    "    :return : retorna dos dataframes corresponents a l'entrenament i al test\n",
    "    \"\"\"\n",
    "    assert split <= 1, 'split must be between 0 and 1'\n",
    "    \n",
    "    row = round(df.shape[0]*split)\n",
    "    #Utilitzem les primeres files (split*100 % de files) per a train\n",
    "    df1 = df.iloc[:row]\n",
    "    #Utilitzem les ultimes files ((1-split)*100 % de files) per a test\n",
    "    df2 = df.iloc[row:]\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(df_train, feat_train, feat_test, df_test=None):\n",
    "    \"\"\"\n",
    "    Funci√≥ que implementa el clasificador Naive_Bayes, √©s a dir entrena amb les\n",
    "    caracter√≠stiques d'entrenament i despr√©s utilitza les probabilitats estimades\n",
    "    per classificar els vectors de test, segons la f√≥rmula\n",
    "    p(C_j|x) = p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)\n",
    "    i agafant la m√†xima.\n",
    "    \n",
    "    Tingues en compte el problema de l'underflow:\n",
    "    log(p(C_j|x)) = log(p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)) =\n",
    "                  = log(P(C_j)) + log(p(x_1|C_j)) + ... + log(p(x_n|C_j))\n",
    "                  \n",
    "    I recorda, per x_i = 0 cal considerar 1 - p(x_1|C_j).\n",
    "    \n",
    "    Si df_test no √©s None, ha de calcular l'encert sobre les dades de test. √âs a dir,\n",
    "    despr√©s de classificar feat_test ha de comparar la classificaci√≥ amb la classe\n",
    "    real i dir (print) quin percentatge d'encert ha obtingut.\n",
    "    \n",
    "    :param df_train: DataFrame amb els tweets que s'utilitzaran per l'entrenament\n",
    "    :param feat_train: Diccionari amb els vectors de caracteristiques de cada tweet de l'entrenament\n",
    "    :param feat_test: Diccionari amb els vectors de caracteristiques de cada tweet de test\n",
    "    :param df_test: En cas d'estar disponible (per Kaggle no hi √©s), \n",
    "        DataFrame amb els tweets que s'utilitzaran pel test\n",
    "    \n",
    "    :return : Una serie on l'index correspon amb els indexos de df_test i els valors s√≥n la\n",
    "        classificaci√≥ retornada per Naive Bayes\n",
    "    \"\"\"\n",
    "    #Calculem les probabilitats marginals condicionades amb la correccio de Laplace\n",
    "    learn = naive_bayes_learn(df_train, feat_train)\n",
    "    #Prenem els partits politics\n",
    "    parties = get_political_party(df_train)\n",
    "    #Prenem la quantitat de tweets que ha fet cada partit politic\n",
    "    num_tw_partits = count_tweet_party(df_train)\n",
    "    #Calculem la probabilitat que un tweet sigui d'un cert partit (en aquest cas no ens cal utilitzar\n",
    "    #la correccio de Laplace perque la probabilitat que un tweet sigui d'un partit sempre sera diferent\n",
    "    #de zero)\n",
    "    prob_parties = num_tw_partits / (count_tweets(df_train))\n",
    "    \n",
    "    #A continuacio, calculem els logaritmes de les probabilitats, per evitar el problema de l'\"underflow\"\n",
    "    #Calculem el logaritme de la probabilitat de cada partit\n",
    "    prob_parties = np.log(prob_parties)\n",
    "    #Calculem el logaritme de la probabilitat que cada paraula apareixi a un tweet de cada partit\n",
    "    prob_yes = np.log(learn)\n",
    "    #Calculem el logaritme de la probabilitat que cada paraula no apareixi a un tweet de cada partit\n",
    "    prob_no = np.log(1-learn)\n",
    "    \n",
    "    #Calculem la probabilitat que cada tweet de test sigui de cada partit\n",
    "    col = [\n",
    "        (prob_parties[party] + (feat_test*prob_yes[party]).sum(axis=1) +\n",
    "         ((~feat_test)*prob_no[party]).sum(axis=1)).tolist() for party in parties\n",
    "    ]\n",
    "    #Creem un pd.Series on l'index correspon amb els indexos de df_test i els valors s√≥n la\n",
    "    #classificacio retornada per Naive Bayes\n",
    "    results = pd.DataFrame(\n",
    "        col, columns = feat_test.index, index=parties\n",
    "    ).T.idxmax(axis=1)\n",
    "    \n",
    "    #Si df_test no es None, retornem el percentatge d'encerts\n",
    "    if (df_test is not None):\n",
    "        encerts = (df_test['party'] == results).sum()\n",
    "        total = df_test.shape[0]\n",
    "        print(\"Percentatge d'encerts: {}/{} = {} %\".format(encerts, total, (encerts/total)*100))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentatge d'encerts: 246/384 = 64.0625 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1536        cs\n",
       "1537     jxcat\n",
       "1538    comuns\n",
       "1539       erc\n",
       "1540       psc\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = split_train_test(df_tweets_train, 0.8)\n",
    "N = 100 # Aquest parametre el podem canviar i fer proves per avaluar quin √©s el millor valor. \n",
    "words_topics = count_words_parties(df_train)\n",
    "top_words = topNwords(df_train, words_topics, N, skip_words)\n",
    "\n",
    "feat_train = create_features(df_train, top_words)\n",
    "feat_test = create_features(df_test, top_words)\n",
    "\n",
    "preds = naive_bayes(df_train, feat_train, feat_test, df_test)\n",
    "    \n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nota\n",
    "El codi que ens ha generat la millor puntuaci√≥ al Kaggle l'hem guardat al Notebook anomenat TestsKaggle.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/t/ef3079700f9e49609ff7a2e70c6fc97e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comuns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comuns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jxcat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jxcat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_topics = count_words_parties(df_tweets_train)\n",
    "N = 200\n",
    "top_words = topNwords(df_tweets_train, words_topics, N, skip_words)\n",
    "\n",
    "feat_train = create_features(df_tweets_train, top_words)\n",
    "feat_test = create_features(df_tweets_test, top_words)\n",
    "\n",
    "result = naive_bayes(df_tweets_train, feat_train, feat_test)\n",
    "result.index.name = 'tweet_id'\n",
    "result.name = 'party'\n",
    "result.to_frame().to_csv('submission.csv')\n",
    "pprint(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
