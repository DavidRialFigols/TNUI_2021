{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook on hi ha la versió millorada del recomanador. Hi ha el codi que ens ha generat la puntuació més alta al Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemes de Recomanació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest segon lliurament es programarà un **sistema de recomanació**, que posarà en correspondència un *usuari* amb *ítems* en funció de les seves preferències i interessos. \n",
    "En aquesta ocasió, implementareu un sistema de recomanació que assisteixi en una compra de supermercat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de començar\n",
    "\n",
    "\n",
    "**\\+ Durant la pràctica, solament es podran fer servir les següents llibreries**:\n",
    "\n",
    "`Pandas, Numpy, Itertools`\n",
    "\n",
    "*Nota: A més de les que ja es troben presents en la 1a cel·la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i paràmetres ja donats**\n",
    "\n",
    "Això no implica però que els hàgiu de fer servir. És a dir, que la funció tingui un paràmetre anomenat `df` no implica que l'hàgiu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica que serà i de quin tipus cada un dels paràmetres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posarà en el pydoc de la funció), `df` sempre serà indicatiu del `Pandas.DataFrame` de les dades. Durant els testos, els paràmetres (i específicament `df`) no contindran les mateixes dades que en aquest notebook, si bé si seran del mateix tipus! Per tant, no us refieu de què tinguin, per exemple, el mateix nombre de files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades\n",
    "\n",
    "### **En aquesta cel·la no féu cap modificació**\n",
    "\n",
    "Descomprimeix els zips a la carpeta \"data\" automàticament. \n",
    "\n",
    "Descarregueu el zip amb les dades del campus i guardeu-lo dins de la carpeta del projecte. **No pugeu cap fitxer de dades a Github** (ja incloem al .gitignore un patró per ignorar-los)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "from os.path import join, dirname\n",
    "\n",
    "def unzip(file):\n",
    "    zip_ref = zipfile.ZipFile(file, 'r')\n",
    "    zip_ref.extractall('data')\n",
    "    zip_ref.close()\n",
    "    \n",
    "unzip('dades_p1.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les dades\n",
    "\n",
    "En aquest i futur notebooks farem servir dades reals corresponents a compres, concretament les utilitzades en el Kaggle Instacart Market Basket Analysis:\n",
    "https://www.kaggle.com/c/instacart-market-basket-analysis\n",
    "\n",
    "\n",
    "* **Order Products**: És el de major interès, conté la relació de productes comprats (`product_id`) per a cada conjunt de compra diferent (`order_id`). A aquests conjunts de compres ens hi referirem com a `ordres`, seguint la nomenclatura de les dades. A més, tot i que no ho farem servir, podríem arribar a saber en quin ordre s'han comprat els productes (`add_to_cart_order`) i inclús si ja s'havia comprat en alguna ordre anterior (`reordered`).\n",
    "\n",
    "* **Orders**: Aquest dataset ens permet relacionar una compra en concret (`order_id`) amb l'usuari que l'ha feta (`user_id`)\n",
    "\n",
    "* **Products**: Donat un `product_id` ens permet obtenir-ne més informació, com ara el nom (`product_name`), la secció en la qual es troba (`aisle_id`) o al departament al qual pertany (`department_id`). Aquests dos últims es complementen amb els conjunts **Aisles** i **Departments**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "### **En aquestes cel·les no feu cap modificació**\n",
    "\n",
    "Carrega les dades en un DataFrame Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_order_prods = pd.read_csv(join('data', 'order_products__train.csv'))\n",
    "    df_orders = pd.read_csv(join('data', 'orders.csv'))[['order_id', 'user_id']]\n",
    "    df_prods = pd.read_csv(join('data', 'products.csv'))[['product_id', 'aisle_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementació\n",
    "\n",
    "Recordeu, seguiu els pydoc i compliu amb el que diuen!\n",
    "\n",
    "El primer que haurem de fer és construir una matriu que ens serveixi, d'alguna forma, com a indicatiu de preferències de cada persona. Per tal efecte, construirem una matriu $m\\times n$, de $m$ usuaris per $n$ items, on cada entrada $i,j$ serà el nombre de vegades que la persona $i$ a comprat l'item $j$.\n",
    "\n",
    "<img src=\"img/Mat.png\">\n",
    "\n",
    "Per saber de quin usuari és cada `order_id`, haureu de creuar el dataset `order_products` amb el `orders`. Una sola persona/usuari tindrà més d'una ordre, mireu quants cops ha comprat els mateixos productes.\n",
    "\n",
    "A més, les dades es componen de molts `product_id diferents`, hi ha massa diversitat entre usuaris. Per tant, per poder recomanar el que farem serà agregar les dades, en lloc de treballar per `product_id` ho farem per `aisle_id`, és a dir \"la secció\" del súper on es troba.\n",
    "\n",
    "Al llarg de la pràctica es parlarà de producte i/o item, perquè és la terminologia estàndard de recomanadors, però sempre serà en referència a `aisle_id` per aquesta pràctica!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_information(df_order_prods, df_orders, df_prods):\n",
    "    \"\"\"\n",
    "    Retorna el dataframe resultant de:\n",
    "        1. Creuar els datasets 'order_products' amb 'orders'.\n",
    "        2. Creuar el dataframe anterior amb 'products'.\n",
    "        Per creuar dos dataframes podeu utilitzar la funció pandas.DataFrame.merge\n",
    "\n",
    "    :param df_order_prods: DataFrame 'order_products'\n",
    "    :param df_orders: DataFrame 'orders'\n",
    "    :param df_prods: DataFrame 'products'\n",
    "    :return: DataFrame descrit prèviament   \n",
    "    \"\"\"\n",
    "    return pd.merge(pd.merge(df_order_prods, df_orders), df_prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_merged = merge_information(df_order_prods, df_orders, df_prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_counts_table(df):\n",
    "    \"\"\"\n",
    "    Retorna un dataframe on les columnes són els `aisle_id`, les files `user_id` i els valors\n",
    "    el nombre de vegades que un usuari ha comprat un producte d'un `aisle_id`\n",
    "    \n",
    "    :param df: DataFrame original després de creuar-lo\n",
    "    :return: DataFrame descrit adalt\n",
    "    \"\"\"\n",
    "    return pd.crosstab(df['user_id'], df['aisle_id'])\n",
    "\n",
    "def get_count(df, user_id, aisle_id):\n",
    "    \"\"\"\n",
    "    Retorna el nombre de vegades que un usuari ha comprat en un `aisle_id`\n",
    "    \n",
    "    :param df: DataFrame retornat per `build_counts_table`\n",
    "    :param user_id: ID de l'usuari\n",
    "    :param aisle_id: ID de la secció\n",
    "    :return: Enter amb el nombre de vegades que ha comprat\n",
    "    \"\"\"\n",
    "    return df.loc[user_id, aisle_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_counts = build_counts_table(df_merged)\n",
    "    count = get_count(df_counts, 14, 5)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenim moltes dades en el nostre dataset, pel que és convenient que les reduïm una mica. Per començar a treballar recomanem que reduïu la mida a aproximadament 0.1 de l'original '(FRAC = 0.1)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcio creada per intentar millorar la puntuacio del Kaggle (finalment, pel resultat mes alt que hem obtingut no l'hem\n",
    "# utilitzada)\n",
    "def filter_data(df_counts):\n",
    "    \"\"\"\n",
    "    Retorna el dataframe resultant d'aplicar una neteja a les dades del parametre\n",
    "    df_counts. Aquesta neteja consisteix en treure els usuaris que han comprat molt\n",
    "    uniformement tots els productes i els usuaris que han comprat molt pocs productes.\n",
    "    \n",
    "    :param df: DataFrame a filtrar\n",
    "    :return: Dataframe resultant d'aplicar una neteja a les dades de 'df_counts'\n",
    "    \"\"\"\n",
    "    # Eliminem els usuaris que hagin comprat molt uniformement, es a dir, aquells en que el vector format pel nombre d'items\n",
    "    # que han comprat de cada tipus de 'aisle_id' tingui una desviacio estandard petita.\n",
    "    users_filtered = df_counts[df_counts.std(axis=1) > 0.15]\n",
    "    \n",
    "    # Eliminem els usuaris que hagin pocs items (hem decidit eliminar els que hagin comprat menys items que la meitat de\n",
    "    # la mitjana d'items que ha comprat cada usuari)\n",
    "    mean = users_filtered.sum(axis=1).mean()\n",
    "    users_filtered = users_filtered[users_filtered.sum(axis=1) > 0.5*mean]\n",
    "    \n",
    "    return users_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    FRAC = 0.0055\n",
    "    df_reduced = df_counts.sample(frac=FRAC, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesurament de similituds\n",
    "\n",
    "El primer pas per poder recomanar és definir una funció de similitud entre vectors. Siguin $x, y$ vectors, de les següents propostes implementa'n mínim una:\n",
    "\n",
    "* Distància euclidea (inversa): https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "\n",
    "$$sim(x, y) = \\frac{1}{1 + \\sqrt{\\sum_i(x_i-y_i)^2}}\\in [0, 1]$$\n",
    "\n",
    "* Similitud cosinus: https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "\n",
    "$$sim(x, y) = \\frac{x\\cdot y}{||x||\\hspace{0.1cm} ||y||} \\in [-1,1]$$\n",
    "\n",
    "* Correlació de Pearson: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "\n",
    "$${\\displaystyle sim(x,y)={\\frac {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{{\\sqrt {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}{\\sqrt {\\sum _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}}}} \\in [-1,1] \\\\ \\text{On }\\bar{x} = \\frac{1}{n} \\sum^n_i x_i\\text{ la mitja (i anàlogament per y)}$$\n",
    "\n",
    "Per implementar qualsevol d'aquestes únicament es permet l'ús de:\n",
    "\n",
    "* `np.sum`\n",
    "* `np.sqrt`\n",
    "* `np.power`\n",
    "* `np.dot`\n",
    "* `np.linalg.norm`\n",
    "* `np.mean`\n",
    "\n",
    "I s'ha de fer **sense bucles**.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Tingueu en compte que les dues últimes funcions consideren valors negatius per exemples oposats (a diferència de la distància euclidea). En cas de fer servir alguna d'aquestes dues, pensa (més endavant) en com afectaran els negatius en la recomanació.\n",
    "\n",
    "En la similitud cosinus, vigileu amb casos on un usuari no ha comprat res, tindreu a ser una divisió entre 0.\n",
    "\n",
    "En la correlació de Pearson, haureu de considerar casos on algun dels dos exemples tingui variància 0, ja que aleshores estareu fent una divisió entre 0. En tals casos, podeu retornar un valor per defecte o alguna de les altres mesures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def similarity(x, y):\n",
    "    \"\"\"\n",
    "    Definir quina de les similituds vols utilitzar  a l'execució.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la similitud\n",
    "    \"\"\"\n",
    "    return pearson(x, y)\n",
    "    \n",
    "def euclid(x, y):\n",
    "    \"\"\"\n",
    "    Retorna la distància euclidiana inversa de dos vectors n-dimensionals.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la distància euclidiana\n",
    "    \"\"\"\n",
    "    return 1/(1+np.linalg.norm(x-y, ord=2))\n",
    "\n",
    "def cosine(x, y):\n",
    "    \"\"\"\n",
    "    Retorna la similitud cosinus de dos vectors n-dimensionals.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la similitud cosinus\n",
    "    \"\"\"\n",
    "    x_norm = np.linalg.norm(x, ord=2)\n",
    "    y_norm = np.linalg.norm(y, ord=2)\n",
    "    \n",
    "    # Si alguna de les dues normes es 0, significa que totes les components d'un dels dos vectors son 0, es a dir,\n",
    "    # que no tenim informacio d'un dels dos vectors. Aixi, retornem -1 com a resultat perque no estan gens relacionats.\n",
    "    if (x_norm == 0 or y_norm == 0):\n",
    "        return -1\n",
    "    #Altrament retornem la formula de la similitud cosinus\n",
    "    return np.dot(x, y)/(x_norm * y_norm)\n",
    "\n",
    "def pearson(x, y):\n",
    "    \"\"\"\n",
    "    Retorna la correlació de Pearson de dos vectors n-dimensionals.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la correlació de Pearson\n",
    "    \"\"\"\n",
    "    first = x - np.mean(x)\n",
    "    second = y - np.mean(y)\n",
    "    norm_first = np.linalg.norm(first, ord=2)\n",
    "    norm_second = np.linalg.norm(second, ord=2)\n",
    "    \n",
    "    # Si alguna de les dues normes es 0, significa que un dels dos vectors te totes les components iguals i a la\n",
    "    # formula estariem dividint per 0. En aquest cas, hem decidit retornar la similitud cosinus entre els dos vectors\n",
    "    # perque la similitud cosinus distingira entre si totes les components del vector son 0 o iguals pero diferents de 0.\n",
    "    if ((norm_first == 0) or (norm_second == 0)):\n",
    "        return cosine(x, y)\n",
    "    #Altrament retornem la formula de la correlacio de Pearson\n",
    "    return np.dot(first, second)/(norm_first*norm_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9258200997725515\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(similarity(np.asarray([1, 1, 1]), np.asarray([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriu de similituds\n",
    "\n",
    "Per fer recomanació col·laborativa existeixen dues opcions, fer un recomanador basat en usuaris o un en ítems:\n",
    "\n",
    "* Recomanador basat en usuaris:\n",
    "Considera la matriu $M\\times N: \\text{usuaris}\\times\\text{items}$, per recomanar t'hauràs de basar en les similituds entre els usuaris.\n",
    "\n",
    "* Recomanador basat en items:\n",
    "Considera la matriu $M\\times N: \\text{items}\\times\\text{usuaris}$, per recomanar t'hauràs de basar en les similituds entre els ítems.\n",
    "\n",
    "Construeix una matriu de mida $M\\times M$ on cada posició $i,j$ indica la distància entre l'element $i$ i el $j$. Així doncs, si estàs fent un recomanador basat en usuaris, `matriu[2, 3]` contindrà la similitud entre l'usuari 2 i el 3. En canvi, si l'estàs fent basat en ítems, `matriu[2, 3]` contindrà la similitud entre l'ítem 2 i el 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hem decidit implementar la funcio similarity_matrix tal i com diu l'apartat opcional de la cel.la seguent.\n",
    "# Es a dir, que el primer parametre es una funcio que hem definit nosaltres que treballa especificament amb matrius\n",
    "# (i no vectors). Hem decidit fer-ho aixi perque tot i que sembla que hi ha molt mes codi, representa una millora\n",
    "# molt important a nivell temporal, sobretot per a valors grans de FRAC.\n",
    "\n",
    "# Funcio que usarem com a parametre per a la funcio similarity_matrix\n",
    "def iter_matrix_similarity(counts, roll_counts):\n",
    "    \"\"\"\n",
    "    Retorna un vector numpy on a la component i-essima hi ha el calcul de la similitud entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \n",
    "    :param counts: matriu de mida M x N\n",
    "    :param roll_counts: matriu de mida M x N\n",
    "    :return: Vector numpy de mida M on a la component i-essima hi ha el calcul de la similitud entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \"\"\"\n",
    "    # Hem decidit usar la correlacio de Pearson com a funcio de similitud, pero podriem usar qualsevol de les 3 funcions\n",
    "    # definides a continuacio\n",
    "    return iter_matrix_pearson(counts, roll_counts)\n",
    "    \n",
    "\n",
    "# Funcio creada per nosaltres per poder fer el calcul de la matriu de similituds de forma matricial\n",
    "# usant la distancia euclidiana (inversa).\n",
    "def iter_matrix_euclid(counts, roll_counts):\n",
    "    \"\"\"\n",
    "    Retorna un vector numpy on a la component i-essima hi ha el calcul de la distancia euclidiana (inversa) entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \n",
    "    :param counts: matriu de mida M x N\n",
    "    :param roll_counts: matriu de mida M x N\n",
    "    :return: Vector numpy de mida M on a la component i-essima hi ha el calcul de la distancia euclidiana (inversa) entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \"\"\"\n",
    "    # Restem les dues matrius i calculem les normes euclidianes per files\n",
    "    partial_sol = np.linalg.norm(counts - roll_counts, ord=2, axis=1)\n",
    "    # Retornem el vector amb la distancia euclidiana (inversa) entre les files de les dues matrius \n",
    "    return 1 / (1 + partial_sol)\n",
    "\n",
    "# Funcio creada per nosaltres per poder fer el calcul de la matriu de similituds de forma matricial\n",
    "# usant la similitud cosinus.\n",
    "def iter_matrix_cosine(counts, roll_counts):\n",
    "    \"\"\"\n",
    "    Retorna un vector numpy on a la component i-essima hi ha el calcul de la similitud cosinus entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \n",
    "    :param counts: matriu de mida M x N\n",
    "    :param roll_counts: matriu de mida M x N\n",
    "    :return: Vector numpy de mida M on a la component i-essima hi ha el calcul de la similitud cosinus entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \"\"\"\n",
    "    # Calculem la norma euclidiana per a cada fila de la matriu counts\n",
    "    counts_norm = np.linalg.norm(counts, ord=2, axis=1)\n",
    "    # Calculem la norma euclidana per a cada fila de la matriu roll_counts\n",
    "    roll_counts_norm = np.linalg.norm(roll_counts, ord=2, axis=1)\n",
    "    \n",
    "    # Si la norma euclidiana de totes les files de la matriu counts i de totes les files de la matriu roll_counts son diferents\n",
    "    # de 0, podem aplicar la similitud cosinus entre cada fila de la matriu counts i de la matriu roll_counts\n",
    "    if (np.all(counts_norm != 0) and np.all(roll_counts_norm != 0)):\n",
    "        # Retornem el vector amb la similitud cosinus entre cada fila de les dues matrius\n",
    "        return np.sum(counts*roll_counts, axis=1)/(counts_norm*roll_counts_norm)\n",
    "    \n",
    "    # Si arribem en aquest punt, significa que en el calcul d'alguna similitud cosinus estariem dividint per 0.\n",
    "    # Creem un vector de zeros que omplirem amb la similitud entre cada fila de les dues matrius\n",
    "    result = np.zeros(counts.shape[0], dtype='float64')\n",
    "    \n",
    "    # Creem una mascara per saber a quines files de la matriu no estariem dividint per 0 si calculessim la similitud cosinus\n",
    "    mask = np.logical_and(counts_norm != 0, roll_counts_norm != 0)\n",
    "    # En aquelles files on es pugui calcular la similitud cosinus, la calculem\n",
    "    result[mask] = np.sum(counts[mask]*roll_counts[mask], axis=1) / (counts_norm[mask]*roll_counts_norm[mask])\n",
    "    # En aquelles files on no es pugui calcular la similitud cosinus perque estariem dividint per 0, posem la similitud a -1,\n",
    "    # seguint la mateixa logica explicada a la funcio cosine de la cel.la anterior\n",
    "    result[np.logical_not(mask)] = -1\n",
    "    # Retornem el vector amb la similitud cosinus entre cada fila de les dues matrius \n",
    "    return result\n",
    "\n",
    "# Funcio creada per nosaltres per poder fer el calcul de la matriu de similituds de forma matricial\n",
    "# usant la correlacio de Pearson.\n",
    "def iter_matrix_pearson(counts, roll_counts):\n",
    "    \"\"\"\n",
    "    Retorna un vector numpy on a la component i-essima hi ha el calcul de la correlacio de Pearson entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \n",
    "    :param counts: matriu de mida M x N\n",
    "    :param roll_counts: matriu de mida M x N\n",
    "    :return: Vector numpy de mida M on a la component i-essima hi ha el calcul de la correlacio de Pearson entre la\n",
    "    fila i-essima de la matriu 'counts' i la fila i-essima de la matriu 'roll_counts'.\n",
    "    \"\"\"\n",
    "    #Restem a cada element de les matrius la mitjana de tota la fila de la matriu\n",
    "    first = counts - counts.mean(axis=1, keepdims=True)\n",
    "    second = roll_counts - roll_counts.mean(axis=1, keepdims=True)\n",
    "    \n",
    "    #Calculem les normes euclidianes de les files de cadascuna de les dues matrius\n",
    "    first_norm = np.linalg.norm(first, ord=2, axis=1)\n",
    "    second_norm = np.linalg.norm(second, ord=2, axis=1)\n",
    "    \n",
    "    # Si les normes euclidianes de totes les files de la matriu first i de totes les files de la matriu second son diferents\n",
    "    # de 0, podem aplicar la correlacio de Pearson entre cada fila de la matriu counts i de la matriu roll_counts\n",
    "    if (np.all(first_norm != 0) and np.all(second_norm != 0)):\n",
    "        # Retornem el vector amb la correlacio de Pearson entre cada fila de les dues matrius\n",
    "        return np.sum(first*second, axis=1)/(first_norm*second_norm)\n",
    "    \n",
    "    # Si arribem en aquest punt, significa que en el calcul d'alguna correlacio de Pearson estariem dividint per 0.\n",
    "    # Creem un vector de zeros que omplirem amb la similitud entre cada fila de les dues matrius\n",
    "    result = np.zeros(first.shape[0], dtype='float64')\n",
    "    # Creem una mascara per saber a quines files de la matriu no estariem dividint per 0 si calculessim la correlacio de Pearson\n",
    "    mask = np.logical_and(first_norm != 0, second_norm != 0)\n",
    "    # En aquelles files on es pugui calcular la correlacio de Pearson, la calculem\n",
    "    result[mask] = np.sum(first[mask]*second[mask], axis=1)/(first_norm[mask]*second_norm[mask])\n",
    "    # Invertim la mascara per saber entre quines files no es pot calcular la correlacio de Pearson\n",
    "    inverted_mask = np.logical_not(mask)\n",
    "    # En aquelles files on no es pugui calcular la correlacio de Pearson perque estariem dividint per 0,\n",
    "    # calculem la similitud cosinus, seguint la mateixa logica explicada a la funcio pearson de la cel.la anterior\n",
    "    result[inverted_mask] = iter_matrix_cosine(counts[inverted_mask], roll_counts[inverted_mask])\n",
    "    # Retornem el vector amb la correlacio de Pearson entre cada fila de les dues matrius\n",
    "    return result\n",
    "\n",
    "def similarity_matrix(similarity_function, df_counts):\n",
    "    \"\"\"\n",
    "    Retorna una matriu de mida M x M on cada posició \n",
    "    indica la similitud entre usuaris (resp. ítems).\n",
    "    \n",
    "    :param similarity_function: Funció que calcularà la similitud \n",
    "        entre usuaris (resp. ítems)\n",
    "    :param df_counts: Dataframe que conté el nombre de vegades que \n",
    "        un usuari ha comprat en un `aisle_id`\n",
    "    :return : Matriu numpy de mida M x M amb les similituds.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_users = df_counts.shape[0]\n",
    "    # Convertim el Dataframe a numpy per fer mes rapid els calculs i poder fer el calcul de la similituds de forma matricial \n",
    "    np_counts = df_counts.values\n",
    "    # Creem una matriu de zeros que anirem omplint amb les similituds a mesura que les anem calculant\n",
    "    sim_matrix = np.zeros((num_users, num_users), dtype='float64')\n",
    "    \n",
    "    # Guardem una copia de la matriu counts. Aquesta copia ens servira per anar-la rotant i anar\n",
    "    # calculant la similitud entre totes les files de la matriu counts\n",
    "    np_roll_counts = np_counts.copy()\n",
    "    \n",
    "    # El nombre d'iteracions que necessitarem usant el metode matricial es (num_users+2)/2 si hi ha un nombre parell\n",
    "    # d'usuaris i (n+1)/2 si hi ha un nombre senar d'usuaris. Aixo es perque la matriu de similituds es simetrica.\n",
    "    num_iter = int((num_users+2) / 2)\n",
    "    if (num_users % 2 != 0):\n",
    "        num_iter = int((num_users+1) / 2)\n",
    "    # Calculem el nombre de columnes (nombre d'items) que te el Dataframe original\n",
    "    num_cols = np_roll_counts.shape[1]\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        # Creem un vector numpy anomenat partial_sol on a cada component i-essima hi ha calculada la similitud entre la\n",
    "        # fila i-essima de la matriu np_counts i la fila i-essima de matriu np_roll_counts.\n",
    "        \n",
    "        # Tractem el cas que el parametre sigui None, seguint les indicacions de l'enunciat de la cel.la seguent\n",
    "        if similarity_function == None:\n",
    "            partial_sol = iter_matrix_similarity(np_counts, np_roll_counts)\n",
    "        # Si el parametre no es None, calculem la similitud amb la funcio passada per parametre\n",
    "        else:\n",
    "            partial_sol = similarity_function(np_counts, np_roll_counts)\n",
    "        \n",
    "        # Si el nombre d'usuaris es parell i estem a l'ultima iteracio, algunes similituds s'hauran calculat dues\n",
    "        # vegades, i per tant eliminem una copia de les similituds que s'han calculat dues vegades\n",
    "        if ((num_users % 2 == 0) and (i == (num_iter - 1))):\n",
    "            # Eliminem una copia de les similituds que s'han calculat dues vegades\n",
    "            partial_sol[int(num_users/2):] = 0\n",
    "        \n",
    "        # Omplim la diagonal amb les similituds calculades. Es a dir, a la posicio (i,i) de la matriu de similituds\n",
    "        # hi posem la similitud entre la fila 'i' de la matriu np_counts i una fila 'j' (que dependra de la iteracio en la que\n",
    "        # ens trobem) de la matriu np_roll_counts\n",
    "        np.fill_diagonal(sim_matrix, partial_sol)\n",
    "        \n",
    "        # Rotem les files de la matriu np_roll_counts. Es a dir, la primera fila de la matriu passa a ser la ultima,\n",
    "        # la segona fila passa a ser la primera, etc. D'aquesta manera, a la seguent iteracio podrem calcular la similitud\n",
    "        # entre files diferents.\n",
    "        np_roll_counts = np.roll(np_roll_counts, -num_cols)\n",
    "        \n",
    "        # Rotem els elements de cada fila de la matriu sim_matrix un lloc cap a l'esquerra.\n",
    "        # Es a dir, el primer element d'una fila passa a ser l'ultim, el segon passa a ser el primer, etc.\n",
    "        # Amb aixo, esfem fent correr la diagonal de la matriu i per tant a la seguent iteracio, quan omplim la diagonal amb\n",
    "        # les noves similituds calculades, les estarem col.locant al lloc que realment els hi correspon.\n",
    "        sim_matrix = np.roll(sim_matrix, -1, axis=1)\n",
    "    \n",
    "    #Finalment, rotem els elements de cada fila de la matriu sim_matrix en sentit contrari tants llocs com els hem fet\n",
    "    # correr abans. Com que en total hem fet 'num_iter' iteracions, desplacem els elements 'num_iter' posicions.\n",
    "    sim_matrix = np.roll(sim_matrix, num_iter, axis=1)\n",
    "    \n",
    "    # Finalment, aprofitem que la matriu es simetrica i li sumem la seva transposada    \n",
    "    sim_matrix = sim_matrix + sim_matrix.T\n",
    "    # Posem 1s a tota la diagonal perque 2 vectors iguals tenen similitud 1 i al sumar la matriu amb la transposada la\n",
    "    # diagonal ha quedat afectada\n",
    "    np.fill_diagonal(sim_matrix, 1)\n",
    "    #Retornem la matriu de similituds\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per cridar aquesta funció, el primer paràmetre pot ser:\n",
    "\n",
    "* Alguna de les funcions que has programat abans (*euclid*, *cosine* o *pearson*) (~@1h 30min treballant directament amb valors de numpy, ~@20h a partir de pandas pur)\n",
    "* Opcionalment (no és obligatori fer-ho) podeu programar una funció que treballi específicament amb matrius (i no vectors). Si ho feu, cal gestionar-ho quan es rep `None`. No totes les funcions anteriorment anomenades són fàcils (ni intuïtives, ni hi caben en memòria) d'aplicar en forma matricial.  (@5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        with open('similarities.pkl', 'rb') as fp:\n",
    "            similarities = pickle.load(fp)\n",
    "    except:\n",
    "        similarities = similarity_matrix(iter_matrix_similarity, df_reduced)\n",
    "        with open('similarities.pkl', 'wb') as fp:\n",
    "            pickle.dump(similarities, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generació de prediccions\n",
    "\n",
    "Per fer recomanació col·laborativa, necessitem una funció que ens doni un valor de quant bona seria la recomanació. En el nostre cas i amb les nostres dades, volem una funció que ens indiqui quants cops compraria un usuari un producte donat.\n",
    "\n",
    "* Si esteu fent un recomanador basat en usuaris, la puntuació per a un usuari $u$ i ítem $j$ és\n",
    "\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\frac{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)\\cdot r_{p,i}}{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)}$$\n",
    "\n",
    "On $r_{u,i}$ indica el nombre de vegades que l'usuari $u$ ha comprat l'l'ítem $i$.\n",
    "\n",
    "És a dir, per cada usuari $p$ diferent de $u$ si aquest usuari ha comprat algun cop el producte $i$, la similitud entre $p$ i $u$ multiplicada pel nombre de vegades que l'usuari $p$ ha comprat l'l'ítem $i$ ($r_{p,i}$).\n",
    "\n",
    "Pondera't per la suma de les similituds.\n",
    "\n",
    "* Anàlogament, si està basat en ítem, la puntuació per a un usuari $u$ i ítem $j$ és\n",
    "\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\frac{\\sum_{j\\neq i,r_{u,j}>0} sim(i, j)\\cdot r_{u,j}}{\\sum_{j\\neq i,r_{u,j}>0} sim(i, j)}$$\n",
    "\n",
    "On $r_{u,i}$ indica el nombre de vegades que l'usuari $u$ ha comprat l'ítem $j$.\n",
    "\n",
    "És a dir, per cada ítem $j$ diferent de $i$ si l'usuari al qui recomanem ha comprat l'ítem $j$, la similitud entre $i$ i $j$ multiplicada pel nombre de vegades que l'usuari al qui recomanem $u$ ha comprat l'ítem $j$ ($r_{u,j}$)\n",
    "\n",
    "Pondera't per la suma de les similituds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos que, sigui quin sigui el cas, al final estem fent el producte vectorial entre dos vectors. Concretament, el producte vectorial entre les similituds i les compres. Fes una funció que calculi aquest resultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(sims, counts):\n",
    "    \"\"\"\n",
    "    * Si estàs implementant basat en usuaris:\n",
    "        Donades les similituds i el nombre de vegades que l'item a recomanar\n",
    "        ha estat comprat per cada usuari, retorna la predicció que indica quants\n",
    "        cops compraria l'usuari un nou ítem.\n",
    "    \n",
    "        :param sims: Similituds entre usuaris\n",
    "        :param counts: Nombre de vegades que l'item a recomanar ha estat comprat per cada usuari\n",
    "        :return : Predicció (float) que indica quants cops compraria l'usuari un ítem.\n",
    "        \n",
    "        \n",
    "    * Si estàs implementant basat en items:\n",
    "         Donades les similituds i el nombre de vegades que l'usuari ha comprat\n",
    "        cada item, retorna la predicció que indica quants cops compraria l'usuari un\n",
    "        nou ítem.\n",
    "    \n",
    "        :param sims: Similituds entre items\n",
    "        :param counts: Nombre de vegades que l'usuari ha comprat cada item\n",
    "        :return : Predicció (float) que indica quants cops compraria l'usuari un ítem.\n",
    "    \"\"\"\n",
    "    return np.dot(sims, counts)/np.sum(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcio millorada. Dona mes importancia als usuaris que son realment semblants. El que fem es multiplicar per 1.3\n",
    "# la similitud dels usuaris que tenen una similitud superior a 0.435\n",
    "def score(user, item, df, similarities):\n",
    "    \"\"\"\n",
    "    Extreu les similituds i el nombre de vegades que cada usuari ha comprat l'ítem de\n",
    "    manera normalitzada (resp. nombre de vegades que un usuari ha comprat cada ítem de manera normalitzada)\n",
    "    i crida a la funció anterior per calcular les prediccions.\n",
    "    \n",
    "    :param user: ID de l'usuari per la predicció\n",
    "    :param item: ID de l'ítem per la predicció\n",
    "    :param df: Dataframe que conté el nombre de vegades que un usuari \n",
    "        ha comprat en un `aisle_id`\n",
    "    :param similarities: Matriu de similituds\n",
    "    :return : Retorna un escalar (float) amb la predicció\n",
    "    \n",
    "    \"\"\"\n",
    "    pos = df.index.get_loc(user)\n",
    "    sims = similarities[pos].copy()\n",
    "    sims[pos]= 0\n",
    "    \n",
    "    # Multipliquem per 1.3 la similitud dels usuaris que tinguin una similitud superior a 0.435 amb l'usuari 'user' \n",
    "    sims[sims > 0.435] = sims[sims > 0.435]*1.3\n",
    "    \n",
    "    counts = df[item]\n",
    "    \n",
    "    return calc_score(sims, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02393478278219381\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(score(df_reduced.index[0], df_reduced.columns[0], df_reduced, similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feu una funció que donat un usuari calculi per cada item que no ha comprat la puntuació d'aquest. La funció retorna els $N$ items més ben puntuats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_n_items(user_id, df, similarities, N):\n",
    "    \"\"\"\n",
    "    Donat un usuari calcula per cada ítem que no ha comprat la puntuació d'aquest. \n",
    "    La funció retorna els $N$ ítems més ben puntuats.\n",
    "    \n",
    "    :param user_id: Identificador de l'usuari\n",
    "    :parma df: Dataframe que conté el nombre de vegades que un usuari \n",
    "        ha comprat en un `aisle_id`\n",
    "    :param similarities: Matriu de similituds\n",
    "    :param N: Nombre d'ítems que volem que siguin recomanats.\n",
    "    :return : Llista amb els IDs dels ítems recomanats\n",
    "    \"\"\"\n",
    "    # Seleccionem el nombre de vegades que l'usuari 'user_id' ha comprat cada item\n",
    "    items = df.loc[user_id]\n",
    "    # Seleccionem els 'aisle_id' d'aquells items que l'usuari 'user_id' no ha comprat\n",
    "    items_not_bought = items[items == 0]\n",
    "    best_items = items_not_bought.index.tolist()\n",
    "    \n",
    "    # Ordenem els 'aisle_id' dels items que l'usuari 'user_id' no ha comprat segons la seva puntuacio\n",
    "    best_items.sort(reverse=True, key=lambda index: score(user_id, index, df, similarities))\n",
    "    \n",
    "    #Retornem els N items amb la puntuacio mes alta\n",
    "    return best_items[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 123, 120, 21, 84, 37, 16, 91, 116, 31]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(recommend_n_items(df_reduced.index[0], df_reduced, similarities, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possibles millores \n",
    "\n",
    "\n",
    "**0) Utilització completa de les dades:**\n",
    "\n",
    "Fer servir `df_original` tindrà (possiblement) resultats més fiables, però trigarà molt més que amb la versió reduida `df`. Pots canviar el `FRAC` a valors més alts ($\\leq 1$) per utilitzar més dades, però compte perque potser la matriu $M\\times M$ no hi cabrà en memòria.\n",
    "\n",
    "**1) Normalització: Prediccions escalades al domini de l'usuari:**\n",
    "Els usuaris compren en diferent mesura els productes, un més quantitat, altres menys. Fent servir la següent formula, escalem la predicció  a la mitja de l'usuari:\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\bar{r_u} + \\frac{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)\\cdot (r_{p,i}-\\bar{r_b})}{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)}$$\n",
    "on $\\bar{r_u}$ és la mitjana de compres de l'usuari *u*.\n",
    "    \n",
    "**2) Valor del nombre d'elements codificats:**\n",
    "Redueix la similitud entre els usuaris si el nombre de productes és baix o descarta (en entrenament) aquells usuaris amb un petit nombre de productes comprats.\n",
    "\n",
    "**3) Augment de la similitud:**\n",
    "Incrementeu el pes als usuaris que són realment similars (~ = 1)\n",
    "\n",
    "**4) Selecció d'usuaris semblants:**\n",
    "Només s'utilitza un subconjunt d'usuaris similars, descartant tots aquells usuaris poc similars.\n",
    "\n",
    "\n",
    "Totes aquestes tècniques es poden aplicar d'igual manera en la recomanació col·laborativa per usuaris o ítems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "\n",
    "Per als usuaris que tens a continuació, quins productes els hi recomanaries (**fins a un màxim de 5**) que compressin segons el que ja han comprat?\n",
    "\n",
    "https://www.kaggle.com/t/f5b5030ef8cc4b5dbe985e6033878c75\n",
    "\n",
    "Si feu modificacions al codi original de cara a millorar els resultats pel Kaggle, feu una còpia d'aquest notebook i treballeu-hi allà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En aquesta primera cel.la generem el DataFrame amb el FRAC que ens ha anat milor al Kaggle\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    df_order_prods = pd.read_csv(join('data', 'order_products__train.csv'))\n",
    "    df_orders = pd.read_csv(join('data', 'orders.csv'))[['order_id', 'user_id']]\n",
    "    df_prods = pd.read_csv(join('data', 'products.csv'))[['product_id', 'aisle_id']]\n",
    "    \n",
    "    df_merged = merge_information(df_order_prods, df_orders, df_prods)\n",
    "    \n",
    "    df_counts = build_counts_table(df_merged)\n",
    "    \n",
    "    FRAC = 0.0055\n",
    "    df_reduced = df_counts.sample(frac=FRAC, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_test_products = pd.read_csv(join('data', 'order_products__test.csv'))\n",
    "    df_test_orders = pd.read_csv(join('data', 'orders__test.csv'))[['order_id', 'user_id']]\n",
    "    df_test_merged = merge_information(df_test_products, df_test_orders, df_prods)\n",
    "    \n",
    "    df_test_counts = build_counts_table(df_test_merged)\n",
    "    df_all = df_reduced.append(df_test_counts)\n",
    "    df_all = df_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>aisle_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300141</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "aisle_id  1    2    3    4    5    6    7    8    9    10   ...  125  126  \\\n",
       "user_id                                                     ...             \n",
       "300140      0    0   24    0    0    0    0    0   24    0  ...    0    0   \n",
       "300141     16    0   20   20   16   14   16   20   20    0  ...    0    0   \n",
       "300142      0    0   15    0   15   18   15   18   18    0  ...    0    0   \n",
       "300143      0    0    0   20    0    0    0    0    0    0  ...    0    0   \n",
       "300144      0    0    0   20   12    0   14    0    0    0  ...    0    0   \n",
       "\n",
       "aisle_id  127  128  129  130  131  132  133  134  \n",
       "user_id                                           \n",
       "300140      0   10    0   10   10    0    0    0  \n",
       "300141      0    0   14    0    0    0    0    0  \n",
       "300142      0    0    0    0   13    0    0    0  \n",
       "300143      0    0    7   20    7    0    0    0  \n",
       "300144      0   14    0    0   20    0    0    0  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tingueu en compte que si voleu fer un canvi a les similarities, heu d'esborrar l'arxiu similarities_test.pkl** (però haureu de recalcular, amb el temps que això suposi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try: \n",
    "        with open('similarities_test.pkl', 'rb') as fp:\n",
    "            similarities_test = pickle.load(fp)\n",
    "    except:\n",
    "        similarities_test = similarity_matrix(iter_matrix_similarity, df_all)\n",
    "        with open('similarities_test.pkl', 'wb') as fp:\n",
    "            pickle.dump(similarities_test, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_submission = pd.DataFrame(columns=['user_id', 'products_list'])\n",
    "\n",
    "    for user_id in df_test_counts.index:\n",
    "        user_recos = recommend_n_items(user_id, df_all, similarities_test, 5)\n",
    "\n",
    "        df_submission = df_submission.append(\n",
    "            {\n",
    "                'user_id': user_id,\n",
    "                'products_list': ' '.join(map(str, user_recos))\n",
    "            }, \n",
    "            ignore_index=True)\n",
    "\n",
    "    df_submission.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id      products_list\n",
      "0  300000    83 84 91 121 88\n",
      "1  300001   84 21 120 112 96\n",
      "2  300002   83 112 121 78 96\n",
      "3  300003  120 108 91 115 31\n",
      "4  300004    24 83 21 112 96\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(df_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan tingueu l'arxiu submission.csv generat, podeu pujar-ho a Kaggle com una submission per veure el vostre score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
